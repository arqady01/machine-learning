寻找一条直线，最大程度拟合样本特征（房屋特征）和样本输出标记（价格）之间的关系

和knn那一章有一个区别，肿瘤的确定与否和两个样本特征有关：肿瘤大小和发现时间，而样本输出标记由是否癌症（单一维度）表示。而本章节横轴是样本特征，纵轴就是样本输出标记了

回归问题中要预测是一个具体的数值，需要占用一个坐标轴；如果要看两个样本特征的回归问题，就要用三维坐标系

样本特征只有一个，称为简单线性回归

# 简单线性回归

通过分析问题，确定问题的损失函数或者效用函数，通过最优化损失函数或者效用函数，获得机器学习的模型

![简单线性回归](https://github.com/arqady01/machine-learning/blob/main/img/linear_regression.png)

假设找到了最佳拟合的直线方程： $y = ax + b$ ，则对于每一个样本点 $x^{(i)}$ ，根据直线方程，预测值为 $\hat{y}^{(i)}=a x^{(i)}+b$ ，真实值为 $y^{i}$ ，二者差距为 $|y^{(i)} - \hat{y}^{(i)}|$ ，但是绝对值表达式不是处处可导的，所以用 ${(y^{(i)} - \hat{y}^{(i)})}^2$ 更贴切，考虑到所有样本，

目标是让 $\sum_{i=1}^{m}(y^{(i)}-\hat{y}^{(i)})^2$ 尽可能小，即找到a和b（x和y是已知的），让 $\sum_{i=1}^{m}(y^{(i)}-ax^{(i)}-b)^2$ 尽可能小，这是典型的最小化二乘法问题

## 最小化二乘法

目标：找到a和b，使得

$$\sum_{i=1}^{m}(y^{(i)}-ax^{(i)}-b)^2$$

最小，不妨让上式表示为 $J(a,b)$ ，分别对a和b求偏导并让其等于0，得到：

$$
\[
\left\{
\begin{matrix}
\frac{\partial J(a,b)}{\partial a} = \sum_{i=1}^{m} 2(y^{(i)} - ax^{(i)} - b)(-x^{(i)}) = 0 \\
\frac{\partial J(a,b)}{\partial b} = \sum_{i=1}^{m} 2(y^{(i)} - ax^{(i)} - b)(-1) = 0
\end{matrix}
\right.
\]
$$
